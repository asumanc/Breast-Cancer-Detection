{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kLZ1GjK_5Gic"
   },
   "source": [
    "## Breast Cancer Detection Using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pb6yORnntQJZ",
    "outputId": "d75d8f18-b13d-4fa8-eb7c-c997434528c4"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv1D, MaxPool1D\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LyNQchx6OG6N"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import  seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "88iXLrvtpJ_x"
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "59fiOhTW9gcI"
   },
   "outputs": [],
   "source": [
    "cancer = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "WhKJM-Xf9gaO",
    "outputId": "2a97c472-79d1-462b-d355-8704af922651"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry \n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
      "        13 is Radius SE, field 23 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "print(cancer.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249
    },
    "colab_type": "code",
    "id": "u4oSNqkN9gYP",
    "outputId": "0fe16ece-8e0b-445c-f339-2cbc32869236"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame(data = cancer.data, columns=cancer.feature_names)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EcLT2XUF9gPt"
   },
   "outputs": [],
   "source": [
    "y = cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "colab_type": "code",
    "id": "YQji4Pcd9gOC",
    "outputId": "068747ec-bd2e-4440-d261-026674745faa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "79QKXZX2xUO6",
    "outputId": "75efe049-34b2-41ca-cf54-1f25b3ea9c59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ABX66MKwxkY0",
    "outputId": "17135543-95a2-4673-c33f-4101dae14194"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_hRM3BDzRX2E"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "I3ZPdhokRX-I",
    "outputId": "541adedb-ade4-46ae-d672-f9313944f870"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 30)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YY5lUqWCRYBa",
    "outputId": "f8ffda47-1ab1-4502-be9c-913a811a1c46"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114, 30)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L2MvuSr6SMZy"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZTSEtD1zRYGj"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(455,30,1)\n",
    "X_test = X_test.reshape(114, 30, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Vhz5hSpRYOv"
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape = (30,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv1D(filters=64, kernel_size=2, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "colab_type": "code",
    "id": "3Q4e5WRdRYRf",
    "outputId": "44bc9419-6feb-4595-8831-2d6a52873456"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_24 (Conv1D)           (None, 29, 32)            96        \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 29, 32)            128       \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 29, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 28, 64)            4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 28, 64)            256       \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 28, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 64)                114752    \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 119,457\n",
      "Trainable params: 119,265\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aQUBL6zwRYUZ"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.00005), loss = 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "TMlxMirSRYZs",
    "outputId": "ef089ddf-a883-4663-cfca-8ec6abecf313"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 114 samples\n",
      "Epoch 1/100\n",
      "455/455 [==============================] - 1s 2ms/sample - loss: 0.9083 - acc: 0.6000 - val_loss: 0.6399 - val_acc: 0.8947\n",
      "Epoch 2/100\n",
      "455/455 [==============================] - 0s 165us/sample - loss: 0.6049 - acc: 0.7407 - val_loss: 0.6060 - val_acc: 0.9211\n",
      "Epoch 3/100\n",
      "455/455 [==============================] - 0s 154us/sample - loss: 0.4778 - acc: 0.7934 - val_loss: 0.5688 - val_acc: 0.9123\n",
      "Epoch 4/100\n",
      "455/455 [==============================] - 0s 144us/sample - loss: 0.4161 - acc: 0.8132 - val_loss: 0.5315 - val_acc: 0.9035\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - 0s 140us/sample - loss: 0.3484 - acc: 0.8571 - val_loss: 0.4968 - val_acc: 0.9035\n",
      "Epoch 6/100\n",
      "455/455 [==============================] - 0s 139us/sample - loss: 0.3366 - acc: 0.8615 - val_loss: 0.4650 - val_acc: 0.9035\n",
      "Epoch 7/100\n",
      "455/455 [==============================] - 0s 143us/sample - loss: 0.3265 - acc: 0.8681 - val_loss: 0.4334 - val_acc: 0.9035\n",
      "Epoch 8/100\n",
      "455/455 [==============================] - 0s 143us/sample - loss: 0.2800 - acc: 0.8769 - val_loss: 0.4043 - val_acc: 0.9035\n",
      "Epoch 9/100\n",
      "455/455 [==============================] - 0s 138us/sample - loss: 0.2528 - acc: 0.8989 - val_loss: 0.3767 - val_acc: 0.9123\n",
      "Epoch 10/100\n",
      "455/455 [==============================] - 0s 132us/sample - loss: 0.2570 - acc: 0.8967 - val_loss: 0.3521 - val_acc: 0.9123\n",
      "Epoch 11/100\n",
      "455/455 [==============================] - 0s 131us/sample - loss: 0.2456 - acc: 0.8901 - val_loss: 0.3278 - val_acc: 0.9123\n",
      "Epoch 12/100\n",
      "455/455 [==============================] - 0s 134us/sample - loss: 0.2103 - acc: 0.9187 - val_loss: 0.3062 - val_acc: 0.9123\n",
      "Epoch 13/100\n",
      "455/455 [==============================] - 0s 132us/sample - loss: 0.2623 - acc: 0.9011 - val_loss: 0.2845 - val_acc: 0.9123\n",
      "Epoch 14/100\n",
      "455/455 [==============================] - 0s 133us/sample - loss: 0.1929 - acc: 0.9187 - val_loss: 0.2637 - val_acc: 0.9123\n",
      "Epoch 15/100\n",
      "455/455 [==============================] - 0s 132us/sample - loss: 0.1623 - acc: 0.9407 - val_loss: 0.2444 - val_acc: 0.9123\n",
      "Epoch 16/100\n",
      "455/455 [==============================] - 0s 132us/sample - loss: 0.1599 - acc: 0.9385 - val_loss: 0.2262 - val_acc: 0.9211\n",
      "Epoch 17/100\n",
      "455/455 [==============================] - 0s 139us/sample - loss: 0.2133 - acc: 0.9121 - val_loss: 0.2112 - val_acc: 0.9211\n",
      "Epoch 18/100\n",
      "455/455 [==============================] - 0s 132us/sample - loss: 0.2153 - acc: 0.9099 - val_loss: 0.1978 - val_acc: 0.9386\n",
      "Epoch 19/100\n",
      "455/455 [==============================] - 0s 132us/sample - loss: 0.1914 - acc: 0.9253 - val_loss: 0.1833 - val_acc: 0.9474\n",
      "Epoch 20/100\n",
      "455/455 [==============================] - 0s 133us/sample - loss: 0.1765 - acc: 0.9385 - val_loss: 0.1718 - val_acc: 0.9649\n",
      "Epoch 21/100\n",
      "455/455 [==============================] - 0s 134us/sample - loss: 0.1485 - acc: 0.9385 - val_loss: 0.1613 - val_acc: 0.9649\n",
      "Epoch 22/100\n",
      "455/455 [==============================] - 0s 134us/sample - loss: 0.1472 - acc: 0.9407 - val_loss: 0.1506 - val_acc: 0.9649\n",
      "Epoch 23/100\n",
      "455/455 [==============================] - 0s 132us/sample - loss: 0.1701 - acc: 0.9429 - val_loss: 0.1422 - val_acc: 0.9649\n",
      "Epoch 24/100\n",
      "455/455 [==============================] - 0s 137us/sample - loss: 0.1680 - acc: 0.9363 - val_loss: 0.1348 - val_acc: 0.9649\n",
      "Epoch 25/100\n",
      "455/455 [==============================] - 0s 141us/sample - loss: 0.1642 - acc: 0.9385 - val_loss: 0.1284 - val_acc: 0.9649\n",
      "Epoch 26/100\n",
      "455/455 [==============================] - 0s 144us/sample - loss: 0.1593 - acc: 0.9319 - val_loss: 0.1218 - val_acc: 0.9649\n",
      "Epoch 27/100\n",
      "455/455 [==============================] - 0s 140us/sample - loss: 0.1424 - acc: 0.9385 - val_loss: 0.1179 - val_acc: 0.9649\n",
      "Epoch 28/100\n",
      "455/455 [==============================] - 0s 139us/sample - loss: 0.1671 - acc: 0.9429 - val_loss: 0.1147 - val_acc: 0.9649\n",
      "Epoch 29/100\n",
      "455/455 [==============================] - 0s 139us/sample - loss: 0.1594 - acc: 0.9319 - val_loss: 0.1113 - val_acc: 0.9649\n",
      "Epoch 30/100\n",
      "455/455 [==============================] - 0s 140us/sample - loss: 0.1605 - acc: 0.9363 - val_loss: 0.1072 - val_acc: 0.9649\n",
      "Epoch 31/100\n",
      "455/455 [==============================] - 0s 141us/sample - loss: 0.1069 - acc: 0.9538 - val_loss: 0.1041 - val_acc: 0.9649\n",
      "Epoch 32/100\n",
      "455/455 [==============================] - 0s 141us/sample - loss: 0.1400 - acc: 0.9451 - val_loss: 0.1009 - val_acc: 0.9737\n",
      "Epoch 33/100\n",
      "455/455 [==============================] - 0s 141us/sample - loss: 0.1423 - acc: 0.9429 - val_loss: 0.0984 - val_acc: 0.9737\n",
      "Epoch 34/100\n",
      "455/455 [==============================] - 0s 141us/sample - loss: 0.1168 - acc: 0.9582 - val_loss: 0.0967 - val_acc: 0.9737\n",
      "Epoch 35/100\n",
      "455/455 [==============================] - 0s 140us/sample - loss: 0.1529 - acc: 0.9319 - val_loss: 0.0947 - val_acc: 0.9737\n",
      "Epoch 36/100\n",
      "455/455 [==============================] - 0s 141us/sample - loss: 0.1357 - acc: 0.9451 - val_loss: 0.0928 - val_acc: 0.9737\n",
      "Epoch 37/100\n",
      "455/455 [==============================] - 0s 135us/sample - loss: 0.1332 - acc: 0.9473 - val_loss: 0.0913 - val_acc: 0.9737\n",
      "Epoch 38/100\n",
      "455/455 [==============================] - 0s 138us/sample - loss: 0.1428 - acc: 0.9429 - val_loss: 0.0907 - val_acc: 0.9737\n",
      "Epoch 39/100\n",
      "455/455 [==============================] - 0s 136us/sample - loss: 0.0949 - acc: 0.9648 - val_loss: 0.0897 - val_acc: 0.9737\n",
      "Epoch 40/100\n",
      "455/455 [==============================] - 0s 133us/sample - loss: 0.1424 - acc: 0.9429 - val_loss: 0.0898 - val_acc: 0.9737\n",
      "Epoch 41/100\n",
      "455/455 [==============================] - 0s 134us/sample - loss: 0.1163 - acc: 0.9604 - val_loss: 0.0896 - val_acc: 0.9649\n",
      "Epoch 42/100\n",
      "455/455 [==============================] - 0s 140us/sample - loss: 0.1238 - acc: 0.9604 - val_loss: 0.0893 - val_acc: 0.9649\n",
      "Epoch 43/100\n",
      "455/455 [==============================] - 0s 145us/sample - loss: 0.1213 - acc: 0.9560 - val_loss: 0.0893 - val_acc: 0.9649\n",
      "Epoch 44/100\n",
      "455/455 [==============================] - 0s 140us/sample - loss: 0.1202 - acc: 0.9582 - val_loss: 0.0888 - val_acc: 0.9649\n",
      "Epoch 45/100\n",
      "455/455 [==============================] - 0s 142us/sample - loss: 0.0994 - acc: 0.9714 - val_loss: 0.0888 - val_acc: 0.9649\n",
      "Epoch 46/100\n",
      "455/455 [==============================] - 0s 138us/sample - loss: 0.1317 - acc: 0.9516 - val_loss: 0.0888 - val_acc: 0.9649\n",
      "Epoch 47/100\n",
      "455/455 [==============================] - 0s 138us/sample - loss: 0.1427 - acc: 0.9385 - val_loss: 0.0886 - val_acc: 0.9649\n",
      "Epoch 48/100\n",
      "455/455 [==============================] - 0s 140us/sample - loss: 0.1135 - acc: 0.9407 - val_loss: 0.0888 - val_acc: 0.9649\n",
      "Epoch 49/100\n",
      "455/455 [==============================] - 0s 141us/sample - loss: 0.1237 - acc: 0.9538 - val_loss: 0.0882 - val_acc: 0.9649\n",
      "Epoch 50/100\n",
      "455/455 [==============================] - 0s 141us/sample - loss: 0.0902 - acc: 0.9670 - val_loss: 0.0874 - val_acc: 0.9649\n",
      "Epoch 51/100\n",
      "455/455 [==============================] - 0s 139us/sample - loss: 0.1461 - acc: 0.9319 - val_loss: 0.0870 - val_acc: 0.9737\n",
      "Epoch 52/100\n",
      "455/455 [==============================] - 0s 139us/sample - loss: 0.0973 - acc: 0.9692 - val_loss: 0.0871 - val_acc: 0.9737\n",
      "Epoch 53/100\n",
      "455/455 [==============================] - 0s 144us/sample - loss: 0.1075 - acc: 0.9648 - val_loss: 0.0876 - val_acc: 0.9737\n",
      "Epoch 54/100\n",
      "455/455 [==============================] - 0s 144us/sample - loss: 0.0820 - acc: 0.9648 - val_loss: 0.0884 - val_acc: 0.9737\n",
      "Epoch 55/100\n",
      "455/455 [==============================] - 0s 138us/sample - loss: 0.1215 - acc: 0.9451 - val_loss: 0.0890 - val_acc: 0.9737\n",
      "Epoch 56/100\n",
      "455/455 [==============================] - 0s 136us/sample - loss: 0.1104 - acc: 0.9626 - val_loss: 0.0892 - val_acc: 0.9737\n",
      "Epoch 57/100\n",
      "455/455 [==============================] - 0s 136us/sample - loss: 0.1031 - acc: 0.9648 - val_loss: 0.0891 - val_acc: 0.9737\n",
      "Epoch 58/100\n",
      "455/455 [==============================] - 0s 135us/sample - loss: 0.1197 - acc: 0.9560 - val_loss: 0.0894 - val_acc: 0.9737\n",
      "Epoch 59/100\n",
      "455/455 [==============================] - 0s 145us/sample - loss: 0.1151 - acc: 0.9692 - val_loss: 0.0888 - val_acc: 0.9737\n",
      "Epoch 60/100\n",
      "455/455 [==============================] - 0s 139us/sample - loss: 0.0691 - acc: 0.9758 - val_loss: 0.0880 - val_acc: 0.9737\n",
      "Epoch 61/100\n",
      "455/455 [==============================] - 0s 138us/sample - loss: 0.0916 - acc: 0.9648 - val_loss: 0.0881 - val_acc: 0.9737\n",
      "Epoch 62/100\n",
      "455/455 [==============================] - 0s 145us/sample - loss: 0.0918 - acc: 0.9604 - val_loss: 0.0870 - val_acc: 0.9737\n",
      "Epoch 63/100\n",
      "455/455 [==============================] - 0s 140us/sample - loss: 0.0999 - acc: 0.9670 - val_loss: 0.0868 - val_acc: 0.9737\n",
      "Epoch 64/100\n",
      "455/455 [==============================] - 0s 139us/sample - loss: 0.0848 - acc: 0.9692 - val_loss: 0.0870 - val_acc: 0.9737\n",
      "Epoch 65/100\n",
      "455/455 [==============================] - 0s 143us/sample - loss: 0.1137 - acc: 0.9626 - val_loss: 0.0863 - val_acc: 0.9737\n",
      "Epoch 66/100\n",
      "455/455 [==============================] - 0s 140us/sample - loss: 0.0921 - acc: 0.9648 - val_loss: 0.0859 - val_acc: 0.9737\n",
      "Epoch 67/100\n",
      "455/455 [==============================] - 0s 142us/sample - loss: 0.1015 - acc: 0.9648 - val_loss: 0.0857 - val_acc: 0.9737\n",
      "Epoch 68/100\n",
      "455/455 [==============================] - 0s 141us/sample - loss: 0.0896 - acc: 0.9714 - val_loss: 0.0859 - val_acc: 0.9737\n",
      "Epoch 69/100\n",
      "455/455 [==============================] - 0s 140us/sample - loss: 0.0982 - acc: 0.9538 - val_loss: 0.0857 - val_acc: 0.9737\n",
      "Epoch 70/100\n",
      "455/455 [==============================] - 0s 141us/sample - loss: 0.0837 - acc: 0.9670 - val_loss: 0.0861 - val_acc: 0.9737\n",
      "Epoch 71/100\n",
      "455/455 [==============================] - 0s 146us/sample - loss: 0.0834 - acc: 0.9604 - val_loss: 0.0863 - val_acc: 0.9737\n",
      "Epoch 72/100\n",
      "455/455 [==============================] - 0s 142us/sample - loss: 0.0945 - acc: 0.9582 - val_loss: 0.0863 - val_acc: 0.9737\n",
      "Epoch 73/100\n",
      "455/455 [==============================] - 0s 139us/sample - loss: 0.1069 - acc: 0.9582 - val_loss: 0.0860 - val_acc: 0.9737\n",
      "Epoch 74/100\n",
      "455/455 [==============================] - 0s 141us/sample - loss: 0.0883 - acc: 0.9670 - val_loss: 0.0861 - val_acc: 0.9737\n",
      "Epoch 75/100\n",
      "455/455 [==============================] - 0s 140us/sample - loss: 0.0772 - acc: 0.9670 - val_loss: 0.0865 - val_acc: 0.9737\n",
      "Epoch 76/100\n",
      "455/455 [==============================] - 0s 140us/sample - loss: 0.0808 - acc: 0.9670 - val_loss: 0.0867 - val_acc: 0.9737\n",
      "Epoch 77/100\n",
      "455/455 [==============================] - 0s 139us/sample - loss: 0.0996 - acc: 0.9692 - val_loss: 0.0866 - val_acc: 0.9737\n",
      "Epoch 78/100\n",
      "455/455 [==============================] - 0s 141us/sample - loss: 0.1068 - acc: 0.9516 - val_loss: 0.0865 - val_acc: 0.9737\n",
      "Epoch 79/100\n",
      "455/455 [==============================] - 0s 139us/sample - loss: 0.0854 - acc: 0.9670 - val_loss: 0.0865 - val_acc: 0.9737\n",
      "Epoch 80/100\n",
      "455/455 [==============================] - 0s 140us/sample - loss: 0.1083 - acc: 0.9670 - val_loss: 0.0862 - val_acc: 0.9737\n",
      "Epoch 81/100\n",
      "455/455 [==============================] - 0s 136us/sample - loss: 0.1006 - acc: 0.9560 - val_loss: 0.0861 - val_acc: 0.9737\n",
      "Epoch 82/100\n",
      "455/455 [==============================] - 0s 138us/sample - loss: 0.0882 - acc: 0.9692 - val_loss: 0.0867 - val_acc: 0.9737\n",
      "Epoch 83/100\n",
      "455/455 [==============================] - 0s 144us/sample - loss: 0.1022 - acc: 0.9626 - val_loss: 0.0873 - val_acc: 0.9737\n",
      "Epoch 84/100\n",
      "455/455 [==============================] - 0s 140us/sample - loss: 0.0711 - acc: 0.9824 - val_loss: 0.0876 - val_acc: 0.9737\n",
      "Epoch 85/100\n",
      "455/455 [==============================] - 0s 145us/sample - loss: 0.0715 - acc: 0.9758 - val_loss: 0.0878 - val_acc: 0.9737\n",
      "Epoch 86/100\n",
      "455/455 [==============================] - 0s 140us/sample - loss: 0.0926 - acc: 0.9692 - val_loss: 0.0884 - val_acc: 0.9737\n",
      "Epoch 87/100\n",
      "455/455 [==============================] - 0s 139us/sample - loss: 0.0723 - acc: 0.9692 - val_loss: 0.0891 - val_acc: 0.9737\n",
      "Epoch 88/100\n",
      "455/455 [==============================] - 0s 140us/sample - loss: 0.0820 - acc: 0.9758 - val_loss: 0.0887 - val_acc: 0.9737\n",
      "Epoch 89/100\n",
      "455/455 [==============================] - 0s 145us/sample - loss: 0.0962 - acc: 0.9604 - val_loss: 0.0883 - val_acc: 0.9737\n",
      "Epoch 90/100\n",
      "455/455 [==============================] - 0s 139us/sample - loss: 0.0904 - acc: 0.9714 - val_loss: 0.0883 - val_acc: 0.9737\n",
      "Epoch 91/100\n",
      "455/455 [==============================] - 0s 141us/sample - loss: 0.0681 - acc: 0.9670 - val_loss: 0.0883 - val_acc: 0.9737\n",
      "Epoch 92/100\n",
      "455/455 [==============================] - 0s 141us/sample - loss: 0.0713 - acc: 0.9736 - val_loss: 0.0885 - val_acc: 0.9737\n",
      "Epoch 93/100\n",
      "455/455 [==============================] - 0s 139us/sample - loss: 0.1046 - acc: 0.9626 - val_loss: 0.0885 - val_acc: 0.9737\n",
      "Epoch 94/100\n",
      "455/455 [==============================] - 0s 151us/sample - loss: 0.0786 - acc: 0.9714 - val_loss: 0.0888 - val_acc: 0.9737\n",
      "Epoch 95/100\n",
      "455/455 [==============================] - 0s 139us/sample - loss: 0.0690 - acc: 0.9802 - val_loss: 0.0892 - val_acc: 0.9737\n",
      "Epoch 96/100\n",
      "455/455 [==============================] - 0s 140us/sample - loss: 0.0918 - acc: 0.9736 - val_loss: 0.0889 - val_acc: 0.9737\n",
      "Epoch 97/100\n",
      "455/455 [==============================] - 0s 139us/sample - loss: 0.0440 - acc: 0.9846 - val_loss: 0.0888 - val_acc: 0.9737\n",
      "Epoch 98/100\n",
      "455/455 [==============================] - 0s 140us/sample - loss: 0.0793 - acc: 0.9780 - val_loss: 0.0893 - val_acc: 0.9737\n",
      "Epoch 99/100\n",
      "455/455 [==============================] - 0s 139us/sample - loss: 0.0811 - acc: 0.9626 - val_loss: 0.0904 - val_acc: 0.9737\n",
      "Epoch 100/100\n",
      "455/455 [==============================] - 0s 142us/sample - loss: 0.0872 - acc: 0.9626 - val_loss: 0.0903 - val_acc: 0.9737\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TYPczgEcRYfI"
   },
   "outputs": [],
   "source": [
    "def plot_learningCurve(history, epoch):\n",
    "  # Plot training & validation accuracy values\n",
    "  epoch_range = range(1, epoch+1)\n",
    "  plt.plot(epoch_range, history.history[\"accuracy\"])\n",
    "  plt.plot(epoch_range, history.history[\"val_accuracy\"])\n",
    "  plt.title('Model accuracy')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.legend(['Train', 'Val'], loc='upper left')\n",
    "  plt.show()\n",
    "\n",
    "  # Plot training & validation loss values\n",
    "  plt.plot(epoch_range, history.history['loss'])\n",
    "  plt.plot(epoch_range, history.history['val_loss'])\n",
    "  plt.title('Model loss')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.legend(['Train', 'Val'], loc='upper left')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nAqpw2S5RYds"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.9083293958024664,\n",
       "  0.6049262403131841,\n",
       "  0.47781707680487373,\n",
       "  0.41605622381954405,\n",
       "  0.34838815868555845,\n",
       "  0.33664350846966545,\n",
       "  0.3265475801059178,\n",
       "  0.2799766577207125,\n",
       "  0.2527986936844312,\n",
       "  0.2570258910184378,\n",
       "  0.24561793289996767,\n",
       "  0.21031167114173974,\n",
       "  0.2622718650888611,\n",
       "  0.19285614425009423,\n",
       "  0.16226344321455274,\n",
       "  0.1598926075375997,\n",
       "  0.21331209998864395,\n",
       "  0.21533426124970992,\n",
       "  0.19144072682074792,\n",
       "  0.1765417706180405,\n",
       "  0.1484956356195303,\n",
       "  0.1472497772384476,\n",
       "  0.17012511367326255,\n",
       "  0.1679833322435945,\n",
       "  0.16421059258691556,\n",
       "  0.15928913873958064,\n",
       "  0.14236321999476506,\n",
       "  0.16707823168445418,\n",
       "  0.15936128536423483,\n",
       "  0.16051875346309535,\n",
       "  0.10691738523297258,\n",
       "  0.14003547238452094,\n",
       "  0.14229180358227464,\n",
       "  0.11681968047089138,\n",
       "  0.15289839608901803,\n",
       "  0.1356775662094191,\n",
       "  0.13320001769851852,\n",
       "  0.14284151569827572,\n",
       "  0.09488721548855959,\n",
       "  0.14243886870726083,\n",
       "  0.11626413097748389,\n",
       "  0.1238205234346154,\n",
       "  0.12128681824593754,\n",
       "  0.12021363223647023,\n",
       "  0.09939911983661599,\n",
       "  0.13167914415960416,\n",
       "  0.14267041119900378,\n",
       "  0.11353751231025863,\n",
       "  0.12374887075479869,\n",
       "  0.09024080082078229,\n",
       "  0.14613011650700164,\n",
       "  0.09732775559628402,\n",
       "  0.10754343762502565,\n",
       "  0.0819905311032966,\n",
       "  0.1214502100106124,\n",
       "  0.11043986350625426,\n",
       "  0.10309920325711533,\n",
       "  0.11973383686208464,\n",
       "  0.11507264048188598,\n",
       "  0.06908836654581867,\n",
       "  0.09159453966460385,\n",
       "  0.0917807373044255,\n",
       "  0.09994050051894161,\n",
       "  0.0847646082659344,\n",
       "  0.11370927577654084,\n",
       "  0.09209963161866744,\n",
       "  0.10152244999349773,\n",
       "  0.089550949714996,\n",
       "  0.0981884393247438,\n",
       "  0.08371927450400787,\n",
       "  0.08341820723080373,\n",
       "  0.09445291787058442,\n",
       "  0.10691267137344067,\n",
       "  0.08832683504692146,\n",
       "  0.07716759011343859,\n",
       "  0.08075694304246168,\n",
       "  0.09959074969065713,\n",
       "  0.10677995699161029,\n",
       "  0.08540397972120535,\n",
       "  0.10829841985807313,\n",
       "  0.10058565143045488,\n",
       "  0.08819643684399345,\n",
       "  0.10217132297764113,\n",
       "  0.07108775403473404,\n",
       "  0.07151472844633755,\n",
       "  0.09262873277395636,\n",
       "  0.07232700943688422,\n",
       "  0.08199313266591711,\n",
       "  0.0961544625051729,\n",
       "  0.0904135933289161,\n",
       "  0.06809401325472109,\n",
       "  0.07133445636584208,\n",
       "  0.10455863467816795,\n",
       "  0.07861848102452663,\n",
       "  0.06899059560600218,\n",
       "  0.09183235343259115,\n",
       "  0.043998569790478594,\n",
       "  0.07927796602003521,\n",
       "  0.08109208310821227,\n",
       "  0.08720541768349134],\n",
       " 'acc': [0.6,\n",
       "  0.74065936,\n",
       "  0.7934066,\n",
       "  0.8131868,\n",
       "  0.85714287,\n",
       "  0.86153847,\n",
       "  0.8681319,\n",
       "  0.8769231,\n",
       "  0.8989011,\n",
       "  0.8967033,\n",
       "  0.8901099,\n",
       "  0.9186813,\n",
       "  0.9010989,\n",
       "  0.9186813,\n",
       "  0.94065934,\n",
       "  0.93846154,\n",
       "  0.9120879,\n",
       "  0.9098901,\n",
       "  0.9252747,\n",
       "  0.93846154,\n",
       "  0.93846154,\n",
       "  0.94065934,\n",
       "  0.94285715,\n",
       "  0.93626374,\n",
       "  0.93846154,\n",
       "  0.93186814,\n",
       "  0.93846154,\n",
       "  0.94285715,\n",
       "  0.93186814,\n",
       "  0.93626374,\n",
       "  0.95384616,\n",
       "  0.94505495,\n",
       "  0.94285715,\n",
       "  0.95824176,\n",
       "  0.93186814,\n",
       "  0.94505495,\n",
       "  0.94725275,\n",
       "  0.94285715,\n",
       "  0.96483517,\n",
       "  0.94285715,\n",
       "  0.96043956,\n",
       "  0.96043956,\n",
       "  0.95604396,\n",
       "  0.95824176,\n",
       "  0.9714286,\n",
       "  0.95164835,\n",
       "  0.93846154,\n",
       "  0.94065934,\n",
       "  0.95384616,\n",
       "  0.96703297,\n",
       "  0.93186814,\n",
       "  0.9692308,\n",
       "  0.96483517,\n",
       "  0.96483517,\n",
       "  0.94505495,\n",
       "  0.96263736,\n",
       "  0.96483517,\n",
       "  0.95604396,\n",
       "  0.9692308,\n",
       "  0.9758242,\n",
       "  0.96483517,\n",
       "  0.96043956,\n",
       "  0.96703297,\n",
       "  0.9692308,\n",
       "  0.96263736,\n",
       "  0.96483517,\n",
       "  0.96483517,\n",
       "  0.9714286,\n",
       "  0.95384616,\n",
       "  0.96703297,\n",
       "  0.96043956,\n",
       "  0.95824176,\n",
       "  0.95824176,\n",
       "  0.96703297,\n",
       "  0.96703297,\n",
       "  0.96703297,\n",
       "  0.9692308,\n",
       "  0.95164835,\n",
       "  0.96703297,\n",
       "  0.96703297,\n",
       "  0.95604396,\n",
       "  0.9692308,\n",
       "  0.96263736,\n",
       "  0.9824176,\n",
       "  0.9758242,\n",
       "  0.9692308,\n",
       "  0.9692308,\n",
       "  0.9758242,\n",
       "  0.96043956,\n",
       "  0.9714286,\n",
       "  0.96703297,\n",
       "  0.9736264,\n",
       "  0.96263736,\n",
       "  0.9714286,\n",
       "  0.9802198,\n",
       "  0.9736264,\n",
       "  0.9846154,\n",
       "  0.978022,\n",
       "  0.96263736,\n",
       "  0.96263736],\n",
       " 'val_loss': [0.6399447468289158,\n",
       "  0.6060108887521845,\n",
       "  0.5687695846222994,\n",
       "  0.531513674217358,\n",
       "  0.49676256901339483,\n",
       "  0.465009143477992,\n",
       "  0.4333563891419193,\n",
       "  0.4043026075028537,\n",
       "  0.3767455209765518,\n",
       "  0.35212601172296626,\n",
       "  0.3278091257078606,\n",
       "  0.3062461138817302,\n",
       "  0.28445974985758465,\n",
       "  0.2636645883321762,\n",
       "  0.24437940486690454,\n",
       "  0.22616353631019592,\n",
       "  0.21122431362930097,\n",
       "  0.19776885603603564,\n",
       "  0.18325935356449663,\n",
       "  0.1717652950370521,\n",
       "  0.16125392600109703,\n",
       "  0.15060611748904512,\n",
       "  0.14223089160626395,\n",
       "  0.13481668814232475,\n",
       "  0.1284135854557941,\n",
       "  0.12177471267549615,\n",
       "  0.11787213646529014,\n",
       "  0.11467830666847396,\n",
       "  0.11128317845756547,\n",
       "  0.10717007818452098,\n",
       "  0.10408462897727364,\n",
       "  0.10089694610551785,\n",
       "  0.09844554411737542,\n",
       "  0.09673855767438286,\n",
       "  0.09471778808521074,\n",
       "  0.09275949994723003,\n",
       "  0.09129552438593748,\n",
       "  0.09069266575470306,\n",
       "  0.0896668264217544,\n",
       "  0.08977792085262767,\n",
       "  0.08961222366544239,\n",
       "  0.08930740832236775,\n",
       "  0.08931899855011388,\n",
       "  0.08880657454331715,\n",
       "  0.08877776803350762,\n",
       "  0.08879010876019795,\n",
       "  0.08862078647341645,\n",
       "  0.08880582327644031,\n",
       "  0.088166708486122,\n",
       "  0.08736734660832506,\n",
       "  0.08700626301007312,\n",
       "  0.08706712961327612,\n",
       "  0.08756025998215926,\n",
       "  0.08839515844980876,\n",
       "  0.088957490105378,\n",
       "  0.08915569313001215,\n",
       "  0.08906889353927813,\n",
       "  0.08937000640128788,\n",
       "  0.08879453741144716,\n",
       "  0.08801464017545968,\n",
       "  0.08813950576280292,\n",
       "  0.0869827094046693,\n",
       "  0.08684720125114709,\n",
       "  0.08700072017024484,\n",
       "  0.08633697869484885,\n",
       "  0.08589775592350123,\n",
       "  0.08568454697205309,\n",
       "  0.08593833936672461,\n",
       "  0.08565216763108446,\n",
       "  0.08606935227126405,\n",
       "  0.08631925737452611,\n",
       "  0.08625051225617267,\n",
       "  0.08604410591355541,\n",
       "  0.08613657964426175,\n",
       "  0.08653262061508078,\n",
       "  0.0866662616792478,\n",
       "  0.08659054626498305,\n",
       "  0.08649994416587185,\n",
       "  0.08652812082385808,\n",
       "  0.08623228731908296,\n",
       "  0.08609318653154269,\n",
       "  0.0867157400700084,\n",
       "  0.08725230500363466,\n",
       "  0.08761320720639146,\n",
       "  0.08776360201208215,\n",
       "  0.08843644303187989,\n",
       "  0.08909616024609197,\n",
       "  0.08870166540145874,\n",
       "  0.08834155243739747,\n",
       "  0.08828403330162952,\n",
       "  0.08827826799007885,\n",
       "  0.08848354115820768,\n",
       "  0.08846784169017746,\n",
       "  0.08881573522822898,\n",
       "  0.08922664742312279,\n",
       "  0.0889343040619503,\n",
       "  0.08877552692827426,\n",
       "  0.08926260366774443,\n",
       "  0.09043910610898022,\n",
       "  0.09029750525951385],\n",
       " 'val_acc': [0.8947368,\n",
       "  0.92105263,\n",
       "  0.9122807,\n",
       "  0.9035088,\n",
       "  0.9035088,\n",
       "  0.9035088,\n",
       "  0.9035088,\n",
       "  0.9035088,\n",
       "  0.9122807,\n",
       "  0.9122807,\n",
       "  0.9122807,\n",
       "  0.9122807,\n",
       "  0.9122807,\n",
       "  0.9122807,\n",
       "  0.9122807,\n",
       "  0.92105263,\n",
       "  0.92105263,\n",
       "  0.9385965,\n",
       "  0.94736844,\n",
       "  0.9649123,\n",
       "  0.9649123,\n",
       "  0.9649123,\n",
       "  0.9649123,\n",
       "  0.9649123,\n",
       "  0.9649123,\n",
       "  0.9649123,\n",
       "  0.9649123,\n",
       "  0.9649123,\n",
       "  0.9649123,\n",
       "  0.9649123,\n",
       "  0.9649123,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9649123,\n",
       "  0.9649123,\n",
       "  0.9649123,\n",
       "  0.9649123,\n",
       "  0.9649123,\n",
       "  0.9649123,\n",
       "  0.9649123,\n",
       "  0.9649123,\n",
       "  0.9649123,\n",
       "  0.9649123,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842,\n",
       "  0.9736842]}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 574
    },
    "colab_type": "code",
    "id": "EdLY6Z2URYYC",
    "outputId": "4831c4b8-e322-41ec-c4ed-b662e7cbba26"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-a795201c4e23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_learningCurve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-100-917b77ea9ba0>\u001b[0m in \u001b[0;36mplot_learningCurve\u001b[0;34m(history, epoch)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;31m# Plot training & validation accuracy values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mepoch_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'accuracy'"
     ]
    }
   ],
   "source": [
    "plot_learningCurve(history, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bf8IW1w0RYMD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AqPb6bPARYKS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "esXzrm3VRYEa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h8MDDtq7RX8L"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "31lWllBzRX5j"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Breast Cancer Detection Using CNN in Python.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
